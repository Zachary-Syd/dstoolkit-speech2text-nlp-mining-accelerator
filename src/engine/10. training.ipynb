{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text classification experimentation notebook \n",
        "\n",
        "This notebook outlines the main processes for transcribing the steps inclusing:\n",
        " 1. Configuring the ML processes and pipelines\n",
        " 2. Digital signal processing (DSP) of the audio files for filtering processes\n",
        " 3. Performng the speech-to-text transcripts for each of the audio files (filtered)\n",
        " 4. Further NLP on the transcripted files to include: key phrase extractio, named entity recognition (NER) and topic modelling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# setup the current paths\n",
        "import os, sys, time\n",
        "currentDir = os.path.dirname(os.getcwd())\n",
        "print(f'Current working directory: {currentDir}')\n",
        "sys.path.append(currentDir)\n",
        "sys.path.append('./../')\n",
        "sys.path.append('././')\n",
        "\n",
        "# system related\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from azureml.core.authentication import AzureCliAuthentication\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# import from common setups & environments\n",
        "from common.constants import *\n",
        "from common.ontology import *\n",
        "from common.azureml_configuration import *\n",
        "from common.general_utilities import *\n",
        "from common.signal_processing import *\n",
        "from common.speech_services import *\n",
        "from common.nlp_modelling import *\n",
        "from common.ml_modelling import *\n",
        "\n",
        "#load the env variables from the hidden file\n",
        "print('Loading environmental variables', load_dotenv(find_dotenv(ENVIORNMENT_FILE)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723367010
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Azure ML Configuration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. configure the azure ml workspace\n",
        "#------------------------------------\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('Configuring the Azure ML services')\n",
        "print('---------------------------------')\n",
        "\n",
        "# get subscription id and other keys from .env file, Other constabst are from source files\n",
        "SUBSCRIPTION_ID = os.environ.get('SUBSCRIPTION_ID')\n",
        "RESOURCE_GROUP = os.environ.get('RESOURCE_GROUP')\n",
        "REGION = os.environ.get('REGION')\n",
        "TENANT_ID = os.environ.get('TENANT_ID')\n",
        "WORKSPACE_NAME = os.environ.get('WORKSPACE_NAME')\n",
        "STORAGE_ACCOUNT = os.environ.get('STORAGE_ACCOUNT')\n",
        "STORAGE_KEY = os.environ.get('STORAGE_KEY')\n",
        "SPEECH_KEY = os.environ.get('SPEECH_KEY')\n",
        "LOCATION=os.environ.get('LOCATION')\n",
        "TEXT_ANALYTICS_KEY = os.environ.get('TEXT_ANALYTICS_KEY')\n",
        "\n",
        "# create the results directories - based on the use_case\n",
        "utilConfig = GeneraltUtilities()\n",
        "utilConfig.createTmpDir(dsp_results_folders)\n",
        "utilConfig.createTmpDir(transcripts_results_folder)\n",
        "utilConfig.createTmpDir(assessed_results_folder)\n",
        "\n",
        "\n",
        "# configure Azure ML services\n",
        "#-----------------------------\n",
        "# initilaise the azureml config class\n",
        "cli_auth = AzureCliAuthentication()\n",
        "azuremlConfig = AzureMLConfiguration(workspace=WORKSPACE_NAME\n",
        "                                    ,tenant_id=TENANT_ID\n",
        "                                    ,subscription_id=SUBSCRIPTION_ID\n",
        "                                    ,resource_group=RESOURCE_GROUP\n",
        "                                    ,location=REGION\n",
        "                                    ,auth=cli_auth)\n",
        "\n",
        "# configure Azure ML workspace\n",
        "azuremlConfig.configWorkspace()\n",
        "\n",
        "# configure the azure ML compute \n",
        "azuremlConfig.configCompute()\n",
        "\n",
        "# configure the experiment(s)\n",
        "azuremlConfig.configExperiment(experiment_name=EXPERIMENT_NAME)\n",
        "\n",
        "# configure the environment - conda\n",
        "azuremlConfig.configEnvironment(environment_name=ENVIRONMENT_NAME)\n",
        "\n",
        "# confogure and register the datastore(s) with Azure ML piplines\n",
        "raw_datastore = azuremlConfig.configDataStore(datastore=RAW_DATASTORE_NAME, container_name=RAW_CONTAINER_NAME)\n",
        "processed_datastore = azuremlConfig.configDataStore(datastore=DSP_DATASTORE_NAME, container_name=DSP_CONATINER_NAME)\n",
        "transcribed_datastore = azuremlConfig.configDataStore(datastore=TRANSCRIBED_DATASTORE_NAME, container_name=TRANSCRIBED_CONATINER_NAME)\n",
        "assessed_datastore = azuremlConfig.configDataStore(datastore=ASSESSED_DATASTORE_NAME, container_name=ASSESSED_CONATINER_NAME)\n",
        "\n",
        "# Prepare the datasets\n",
        "#------------------------\n",
        "# register the datasets associated with the datastore - recordings\n",
        "raw_recordings_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path= RECORDINGS_FOLDER, \n",
        "                                            dataset_name=RECORDINGS_DATASET_NAME, description='raw datasets')\n",
        "\n",
        "# register the datasets associated with the datastore - truth transcription provided\n",
        "truth_transcribed_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path = TRUTH_TRANSCRIPTED_FOLDER, \n",
        "                                            dataset_name=TRUTH_DATASET_NAME, description='truth transcripted datasets')\n",
        "\n",
        "# register the datasets associated with the datastore - key phrases\n",
        "key_phrases_datasets = azuremlConfig.configDatasets(datastore=raw_datastore, file_path = ONTOLOGY_FOLDER, \n",
        "                                            dataset_name=ONTOLOGY_DATASET_NAME, description='ontology datasets')\n",
        "\n",
        "# register the datasets associated with the datastore - assessed data\n",
        "assessed_datasets = azuremlConfig.configDatasets(datastore=assessed_datastore, file_path = RESULTS_ASSESSED_PATH, \n",
        "                                            dataset_name=ASSESSED_DATASET_NAME, description='assessed datasets')\n",
        "\n",
        "# Mount the datasets\n",
        "# ---------------------\n",
        "# mount the datasets - note; providing the root path since dataset name has the embedded path\n",
        "raw_recordings_datasets_context, raw_recordings_datasets_mounted = azuremlConfig.downloadDatasets(datasets_registered=raw_recordings_datasets, \n",
        "                                                download_path=RECORDINGS_MOUNT_PATH)\n",
        "\n",
        "# mount the truth datasets\n",
        "truth_transcribed_datasets_context, truth_transcribed_datasets_mounted = azuremlConfig.downloadDatasets(datasets_registered=truth_transcribed_datasets, \n",
        "                                                download_path=TRUTH_MOUNT_PATH)\n",
        "\n",
        "# mount the datasets - note; providing the root path since dataset name has the embedded path \n",
        "key_phrases_datasets_context, key_phrases_datasets_mounted = azuremlConfig.downloadDatasets(datasets_registered=key_phrases_datasets, \n",
        "                                                download_path=ONTOLOGY_MOUNT_PATH)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723391022
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Ontology Processing\n",
        "\n",
        "We import some definition to analyze audio files \n",
        "- `ontology_list` defines (TBA)\n",
        "- `KEY_PHRASES_SEARCH_FILENAME` defines special keywords and their categories to use text analytics.\n",
        "- `HOMOPHONE_LIST_FILENAME` is used to replace extract keywords."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. configure the ontology and corpus\n",
        "# ------------------------------------\n",
        "print('Prepare the ontology')\n",
        "print('--------------------')\n",
        "\n",
        "ontology = Ontology()\n",
        "enhance = True\n",
        "\n",
        "# configure the ontologies, and any enhancements (if required)\n",
        "# pass the list of ontologies of interest and configure\n",
        "ontology_list = [GENERAL_ONTOLOGY_FILENAME]\n",
        "\n",
        "# enahnce the radio-check ontology\n",
        "ontology.configOntology(ONTOLOGY_MOUNT_PATH, ontology_list, ontology_to_enhance=None)\n",
        "\n",
        "# configure the key phrase for searching dictionary\n",
        "ontology.configKeyPhraseSearch(f'{ONTOLOGY_MOUNT_PATH}{KEY_PHRASES_SEARCH_FILENAME}')\n",
        "\n",
        "# configure the homophone list (word replacement list)\n",
        "ontology.configHomophone(f'{ONTOLOGY_MOUNT_PATH}{HOMOPHONE_LIST_FILENAME}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723401742
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Audio Signal Processing (DSP)\n",
        "\n",
        "In this process, we do pre-processing for analyzing like noise reduction for each audio file before actual analyzing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. perform audio filtering processes\n",
        "#-------------------------------------\n",
        "print('Perforing audio signal processing (DSP)')\n",
        "print('---------------------------------------')\n",
        "\n",
        "# setup filtering\n",
        "filterAudio = SignalProcessing()\n",
        "\n",
        "# option to apply butterworth filter\n",
        "butterworth_filter = True\n",
        "\n",
        "# obtain the mounted audio files to perform the ML pipelines\n",
        "# only extract files that are audio within the mounted datasets\n",
        "raw_audio_files = [x for x in raw_recordings_datasets_mounted if x.endswith('.wav')]\n",
        "\n",
        "# loop though each audio file and perform DSP\n",
        "for raw_audio_file in raw_audio_files:\n",
        "    print(f'Performing DSP (filtering) for audio file : {raw_audio_file}')\n",
        "    \n",
        "    # configure the filter\n",
        "    filterAudio.configFilter(low_freq_cut=LOW_FREQ_CUTOFF, high_freq_cut=HIGH_FREQ_CUTOFF,\n",
        "                            order=FILTER_ORDER)\n",
        "\n",
        "    # read the audio file for the byte data and the sampling rate\n",
        "    # through the class fields \n",
        "    filterAudio.readAudioFile(audio_file_name=raw_audio_file, mount_path=RECORDINGS_MOUNT_PATH, stereo=False)\n",
        "    # apply the butterworth filter\n",
        "    if butterworth_filter:\n",
        "        filterAudio.butterworthFilter()\n",
        "\n",
        "    # apply further noise reduction\n",
        "    filterAudio.fftFilter(stationary=True, thresh_stationary=THRESH_STATIONARY, prop_decrease=PROP_DECREASE, freq_smooth=FREQ_MASK_SMOOTH)\n",
        "\n",
        "    # save the audio filtered files\n",
        "    filterAudio.saveAudioFiltered(filtered_audio_file_path=dsp_results_folders, volume=12, fix_Name=True)\n",
        "\n",
        "# also save to datastore\n",
        "filterAudio.saveAudioFilteredtoDatastore(datastore=processed_datastore, \n",
        "                            filtered_audio_file_path=dsp_results_folders, target_path=RECORDINGS_FOLDER)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Speech to Text Processing\n",
        "\n",
        "We execute Text processing using Speech Service in Azure Cognitive Service to extract the sentence which are inside audio files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. perform the speech-to-text \n",
        "# -----------------------------\n",
        "print('Performing speech-to-text transcription')\n",
        "print('---------------------------------------')\n",
        "\n",
        "#setup\n",
        "validate = True\n",
        "filtered = True\n",
        "\n",
        "# initilaise the speech to text\n",
        "speech = AzureCognitiveSpeechServices(speech_key=SPEECH_KEY, location=LOCATION, validate=validate, filtered=filtered)\n",
        "\n",
        "# prepare the ground truth transcripted text\n",
        "if validate:\n",
        "    speech.processTranscriptsTruth(f'{TRUTH_MOUNT_PATH}{TRANSCRIPTS_TRUTH_FILENAME}')\n",
        "\n",
        "# select wich folder to point to\n",
        "if filtered:\n",
        "    audio_folder = dsp_results_folders\n",
        "    file_flag = f'_filtered{FILE_FLAG}'\n",
        "else:\n",
        "    audio_folder = RECORDINGS_MOUNT_PATH\n",
        "    file_flag = FILE_FLAG\n",
        "\n",
        "\n",
        "# loop through each audio file and perform transcription\n",
        "if len(os.listdir(audio_folder)) > 0:\n",
        "    audio_files = os.listdir(audio_folder)\n",
        "    audio_files = [x for x in audio_files if x.endswith(file_flag)]\n",
        "        \n",
        "    # loop through each mounted dataset and perform the speech-to-text process\n",
        "    # the audio file to transcribe\n",
        "    for audio_file in audio_files:\n",
        "        print(f'Starting the filtered transcription for file: {audio_file}')\n",
        "        \n",
        "        # configure, \n",
        "        speech.configSpeechtoText(audio_file, file_path=audio_folder, add_phrases=True, dictionary=ontology.main_dictionary)\n",
        "        \n",
        "        # transcribe - also applying time delay to avoid race conditions\n",
        "        time.sleep(0.25)\n",
        "        speech.transcribeAudioFile()\n",
        "    \n",
        "        # format results, with the option of applying homophone list\n",
        "        speech.transcribeResults(homophone_list = ontology.homophone_list)\n",
        "      \n",
        "    # perform validation (if required)    \n",
        "    if validate:\n",
        "        speech.werAnalysis()\n",
        "        print('The average WER is:', speech.transcript_performance_df['wer'].mean())\n",
        "    \n",
        "    # convert results to dataframe also\n",
        "    speech.processDataframe()\n",
        "    \n",
        "    # save results to datastore \n",
        "    speech.saveTranscripts(datastore=transcribed_datastore, file_path = transcripts_results_folder, \n",
        "                            target_path = f'{use_case}/')\n",
        "        \n",
        "else:\n",
        "    print('could not transcibe the filtered audio files')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723663063
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## V. NLP Modelling\n",
        "\n",
        "We continue NLP modelling with transcribed data, where we tokenize transcript, remove stopwords, extract nouns, keyphrase extraction, etc.\n",
        "\n",
        "These extracted features are used in `Advanced modelling` for classifying the audio files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. NLP Analysis\n",
        "#---------------------\n",
        "print('Performing NLP modelling')\n",
        "print('------------------------')\n",
        "\n",
        "# setup\n",
        "read_from_memory = False\n",
        "\n",
        "# setup paths and previously transcribed files (if required)\n",
        "assessed_results_folder =  f'{RESULTS_PATH}{RESULTS_ASSESSED_PATH}{use_case}/' \n",
        "transcribed_file_path = f'{transcripts_results_folder}{TRANSCRIBED_JSON_FILENAME}'\n",
        "transcribed_df_file_path = f'{transcripts_results_folder}{TRANSCRIBED_DATAFRAME_FILENAME}'\n",
        "\n",
        "# read the transcripted distionary, either from disk or memeory\n",
        "if read_from_memory:\n",
        "    transcripted_dictionary = speech.transcripted_dict_all\n",
        "    transcripted_df = speech.transcripted_dataframe_all\n",
        "else:\n",
        "    with open(transcribed_file_path, 'r') as read_file:\n",
        "        transcripted_dictionary = json.load(read_file)\n",
        "    transcripted_df = pd.read_csv(transcribed_df_file_path, encoding = 'unicode_escape', engine ='python').reset_index(drop=True)\n",
        "\n",
        "\n",
        "# initialise the NLP service class\n",
        "nlp = NLPModelling(cogs_url=COGS_URL, nlp_key=TEXT_ANALYTICS_KEY)\n",
        "\n",
        "# perform steps of the NLP\n",
        "if (transcripted_dictionary is not None):\n",
        "\n",
        "    # perform the tokenization\n",
        "    nlp.tokenizeTranscript(transcripted_dictionary)\n",
        "\n",
        "    # perform the stop word filtering - passed the calss field as argument\n",
        "    nlp.removeStopWords(nlp.tokenized_dict_all) \n",
        "\n",
        "    # extract the nouns from the tokenised dictionary\n",
        "    nlp.nounExtraction(nlp.filtered_tokenized_dict_all)\n",
        "\n",
        "    # perform key phrase extraction - on original transcribes\n",
        "    nlp.keyPhraseExtraction(nlp_url=NLP_KEY_PHRASE_URL, body=transcripted_dictionary) \n",
        "\n",
        "    # perform non-domain specific NER extraction - on original transcribes\n",
        "    nlp.nerExtraction(nlp_url=NLP_NER_URL, body=transcripted_dictionary)\n",
        "\n",
        "    # extract custom key interests - on original transcribes\n",
        "    nlp.customKeyPhraseExtraction(text_dictionary=transcripted_dictionary, main_dictionary=ontology.main_dictionary,\n",
        "                                    key_phrase_dictionary=ontology.key_phrase_search_dictionary, word_to_num_dict=ontology.word_to_num_dict)\n",
        "    \n",
        "    # process the NLP results\n",
        "    nlp.processNLPResults(transcripted_dictionary)\n",
        "\n",
        "    # save the MLP results to local and datastore \n",
        "    nlp.saveNLPResults(datastore=assessed_datastore, file_path = assessed_results_folder, target_path = f'{use_case}/', \n",
        "                        transcript_dataframe=transcripted_df)\n",
        "\n",
        "else:\n",
        "    print(f'Transcripted dictionary {transcripted_dictionary} is empty')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723692313
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Advanced Modelling\n",
        "\n",
        "We classify audio files with machine learning techniques, where target column is defined in variable `MESSAGE_CLASSIFICATION_GROUP`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ML Modelling\n",
        "# ---------------\n",
        "print('Performing ML classification modelling')\n",
        "print('--------------------------------------')\n",
        "\n",
        "# setup\n",
        "EDA = True\n",
        "\n",
        "autoML = False\n",
        "train = True\n",
        "heuristic = False\n",
        "\n",
        "# initialise the ml class\n",
        "ml_modelling = MLModelling()\n",
        "\n",
        "# prepare the ml dataframe\n",
        "ml_modelling.configMLDataframe(nlp.nlp_dataframe_all, normalize=False)\n",
        "\n",
        "# reduce the ML dataframe ready for modelling\n",
        "ml_modelling.prepareMLDataframe(train = True)\n",
        "\n",
        "# prepare the train and test split\n",
        "ml_modelling.prepareTrainTestSplit(test_size=0.33)\n",
        "\n",
        "# apply special case of random forest\n",
        "ml_modelling.randomForest_special(plot=False, model_path=f'{assessed_results_folder}RandomForest-Special')\n",
        "\n",
        "# save the ML dataframe\n",
        "ml_modelling.saveMLResults(datastore=assessed_datastore, \n",
        "                            file_path=assessed_results_folder, \n",
        "                            ml_file_name='ML_dataframe.csv', \n",
        "                            all_file_name='NLP_dataframe.csv', \n",
        "                            target_path = f'{use_case}/', \n",
        "                            ml_dataframe=ml_modelling.ml_dataframe_all, \n",
        "                            all_dataframe=nlp.nlp_dataframe_all)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663723709458
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VII. Submit Experiment\n",
        "\n",
        "This cell shows an example for using Azure ML pipelines about training Machine Learning model with `train.py` script.\n",
        "\n",
        "You can change it as your need."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Assign csv file for preparing pandas Dataframe\n",
        "ML_DATFRAME_FILENAME = 'NLP_dataframe.csv'\n",
        "\n",
        "base_dir = f'{os.getcwd()}/'\n",
        "\n",
        "TRAIN_PATH = base_dir + '../'\n",
        "TRAIN_FILENAME = 'engine/machine_learning/train.py'\n",
        "\n",
        "results_file_path_full = assessed_datasets.as_mount()\n",
        "\n",
        "train_arg_list = ['--data-folder', results_file_path_full , \n",
        "                '--file-name', ML_DATFRAME_FILENAME, \n",
        "                '--regularization', 0.5,\n",
        "                '--workspace', WORKSPACE_NAME,\n",
        "                '--tenant_id', TENANT_ID,\n",
        "                '--subscription_id', SUBSCRIPTION_ID,\n",
        "                '--resource_group', RESOURCE_GROUP, \n",
        "                '--location', REGION, \n",
        "                '--datastore', ASSESSED_DATASTORE_NAME,\n",
        "                '--container_name', ASSESSED_CONATINER_NAME\n",
        "                ]\n",
        "\n",
        "## Define configuration for experiments\n",
        "ml_modelling.configScriptRun(arg_list=train_arg_list, \n",
        "                            script_dir = TRAIN_PATH, \n",
        "                            script= TRAIN_FILENAME, \n",
        "                            compute_target = azuremlConfig.compute_target, \n",
        "                            environment=azuremlConfig.environment)\n",
        "\n",
        "run = azuremlConfig.experiment.submit(config = ml_modelling.script_run_config)\n",
        "run\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1663725173204
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VIII. Cleanup"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "azuremlConfig.removeLocalDatasets(remove_path = RECORDINGS_MOUNT_PATH)\n",
        "azuremlConfig.removeLocalDatasets(remove_path = TRUTH_MOUNT_PATH)\n",
        "azuremlConfig.removeLocalDatasets(remove_path = ONTOLOGY_MOUNT_PATH)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Error in: [Errno 2] No such file or directory: '1249120_44142156_65967262.wav'\nNo dataset files to remove.\nNo dataset files to remove.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1663725222885
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}